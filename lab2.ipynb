{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3d92306",
      "metadata": {
        "id": "e3d92306"
      },
      "source": [
        "\n",
        "# Lecture 2 - CNN and transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba0343b2",
      "metadata": {
        "id": "ba0343b2"
      },
      "source": [
        "In this tutorial we firstly investigate how to implement models based on CNNs in tensorflow/keras and secondly we will se some examples of how to transfer the knowledge between different tasks.\n",
        "For the following instances we will be using:\n",
        "\n",
        "- <b> tensroflow/keras </b>\n",
        "- <b> matplotlib </b>\n",
        "- <b> numpy </b> "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ddc9c6",
      "metadata": {
        "id": "72ddc9c6"
      },
      "source": [
        "### Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4daaa28a",
      "metadata": {
        "id": "4daaa28a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import PIL \n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e52676dc",
      "metadata": {
        "id": "e52676dc"
      },
      "source": [
        "### Download and prepare the dataset\n",
        "\n",
        "\n",
        "This tutorial shows how to classify images of flowers. It creates an image classifier using a `keras` model, and loads data using `tf.keras.utils.image_dataset_from_directory`. \n",
        "\n",
        "The first model building example follows a basic machine learning workflow:\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cddf0a1",
      "metadata": {
        "id": "6cddf0a1"
      },
      "source": [
        "This tutorial uses a dataset of about 3,700 photos of flowers. The dataset contains five sub-directories, one per class:\n",
        "\n",
        "```\n",
        "flower_photo/\n",
        "  daisy/\n",
        "  dandelion/\n",
        "  roses/\n",
        "  sunflowers/\n",
        "  tulips/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84d93d4",
      "metadata": {
        "id": "c84d93d4"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcbcee61",
      "metadata": {
        "id": "bcbcee61"
      },
      "source": [
        "Let's inspect the dataset and show some samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db106f50",
      "metadata": {
        "id": "db106f50"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91b1233e",
      "metadata": {
        "id": "91b1233e"
      },
      "outputs": [],
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56c6197f",
      "metadata": {
        "id": "56c6197f"
      },
      "outputs": [],
      "source": [
        "tulips = list(data_dir.glob('tulips/*'))\n",
        "PIL.Image.open(str(tulips[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86043766",
      "metadata": {
        "id": "86043766"
      },
      "source": [
        "# Load data using a Keras utility\n",
        "\n",
        "Let's load these images off disk using the helpful `tf.keras.utils.image_dataset_from_directory` utility. This will take you from a directory of images on disk to a `tf.data.Dataset` in just a couple lines of code. If you like, you can also write your own data loading code from scratch by visiting the [Load and preprocess images](../load_data/images.ipynb) tutorial.\n",
        "We will divide the images in train and test set."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "376e4448",
      "metadata": {
        "id": "376e4448"
      },
      "source": [
        "Some fixed parameters for the dataset loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c58f2a8b",
      "metadata": {
        "id": "c58f2a8b"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "d1 = 180\n",
        "d2 = 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "455ef9bd",
      "metadata": {
        "id": "455ef9bd"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=seed,\n",
        "  image_size=(d1, d2),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=seed,\n",
        "  image_size=(d1, d2),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959118f9",
      "metadata": {
        "id": "959118f9"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "num_classes = len(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39b9f628",
      "metadata": {
        "id": "39b9f628"
      },
      "source": [
        "## Visualize the data\n",
        "\n",
        "Here are the first nine images from the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20f0e67f",
      "metadata": {
        "id": "20f0e67f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c2371f",
      "metadata": {
        "id": "29c2371f"
      },
      "source": [
        "## Create the convolutional model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d77678e1",
      "metadata": {
        "id": "d77678e1"
      },
      "source": [
        "In order to map all the channels of the images in the range [0, 1], we can apply a [Rescaling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling) layer to normalize the input.\n",
        "\n",
        "The lines of code below define the convolutional base using a common pattern: a stack of [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers.\n",
        "\n",
        "As input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368c93c0",
      "metadata": {
        "id": "368c93c0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Rescaling\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def get_model(input_shape):\n",
        "    x = Input(shape=input_shape)\n",
        "\n",
        "    r = Rescaling(1./255)(x)\n",
        "\n",
        "    c1 = Conv2D(16, 3, padding='same', activation='relu')(r)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    c2 = Conv2D(32, 3, padding='same', activation='relu')(p1)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    c3 = Conv2D(64, 3, padding='same', activation='relu')(p2)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    f = Flatten()(p3)\n",
        "    d1 = Dense(128, activation='relu')(f)\n",
        "    d2 = Dense(num_classes)(d1)\n",
        "\n",
        "    model = Model(x, d2)\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = get_model((d1, d2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfd335e5",
      "metadata": {
        "id": "cfd335e5"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a last layer with a `softmax` activation and `SparseCategoricalCrossentropy(from_logits = False)` is theoretically equivalent to omit the activation function and set `from_logits = True`. \n",
        "This, though, in tensorflow is not always true and it is always better to exploit the `from_logits` parameter, [here](https://stackoverflow.com/questions/61233425/what-should-i-use-as-target-vector-when-i-use-binarycrossentropyfrom-logits-tru/61237426#61237426) you can find some reasons why."
      ],
      "metadata": {
        "id": "AIc75hC2QjhT"
      },
      "id": "AIc75hC2QjhT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e806c9a1",
      "metadata": {
        "id": "e806c9a1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956ec27a",
      "metadata": {
        "id": "956ec27a"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da5756a9",
      "metadata": {
        "id": "da5756a9"
      },
      "outputs": [],
      "source": [
        "print(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "047f7016",
      "metadata": {
        "id": "047f7016"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "history = model.fit(train_ds, epochs=10, validation_data = validation_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2vmIjacemip-",
      "metadata": {
        "id": "2vmIjacemip-"
      },
      "source": [
        "Let's inspect our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761be3c6",
      "metadata": {
        "id": "761be3c6"
      },
      "outputs": [],
      "source": [
        "# We can also use the history (that we saved before) to check the behavior of the training.\n",
        "# history is a Python dictionary that cointains the values of the behavior of the loss\n",
        "# during training (one value for each epoch).\n",
        "def display_history(history):\n",
        "    mse_training = history.history['loss']\n",
        "    acc_training = history.history['accuracy']\n",
        "\n",
        "    mse_val = history.history['val_loss']\n",
        "    acc_val = history.history['val_accuracy']\n",
        "\n",
        "    # Visualize the behavior of the loss\n",
        "    plt.plot(mse_training)\n",
        "    plt.plot(mse_val)\n",
        "    plt.grid()\n",
        "    plt.title('Loss during training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.show()\n",
        "\n",
        "    # and of the accuracy\n",
        "    plt.plot(acc_training)\n",
        "    plt.plot(acc_val)\n",
        "    plt.grid()\n",
        "    plt.title('Accuracy during training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a33ed1",
      "metadata": {
        "id": "58a33ed1"
      },
      "outputs": [],
      "source": [
        "display_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hddbCcvKmqvW",
      "metadata": {
        "id": "hddbCcvKmqvW"
      },
      "source": [
        "## Overfitting elimination techniques\n",
        "\n",
        "In the plots above, the training performances are increasing linearly over time, whereas validation ones are getting worse. Also, the difference in accuracy between training and validation accuracy is a noticeable sign of [overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit).\n",
        "\n",
        "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
        "\n",
        "There are multiple ways to fight overfitting in the training process. In this tutorial, you'll use *data augmentation* and add *Dropout* to your model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2IG5ZKV5m4En",
      "metadata": {
        "id": "2IG5ZKV5m4En"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sBGPABXzm3EX",
      "metadata": {
        "id": "sBGPABXzm3EX"
      },
      "source": [
        "Overfitting generally occurs when there are a small number of training examples. [Data augmentation](./data_augmentation.ipynb) takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. This helps expose the model to more aspects of the data and generalize better.\n",
        "\n",
        "You will implement data augmentation using the following Keras preprocessing layers: `tf.keras.layers.RandomFlip`, `tf.keras.layers.RandomRotation`, and `tf.keras.layers.RandomZoom`. These can be included inside your model like other layers, and run on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hsI2FHB0myDB",
      "metadata": {
        "id": "hsI2FHB0myDB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "\n",
        "data_augmentation = lambda input_shape: tf.keras.Sequential([\n",
        "    RandomFlip(\"horizontal\", input_shape=input_shape),\n",
        "    RandomRotation(0.1),\n",
        "    RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GBSuanRSnOeb",
      "metadata": {
        "id": "GBSuanRSnOeb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = (data_augmentation((d1, d2, 3)))(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nSHVEfM4nSIZ",
      "metadata": {
        "id": "nSHVEfM4nSIZ"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "Another technique to reduce overfitting is to introduce [dropout](https://developers.google.com/machine-learning/glossary#dropout_regularization) regularization to the network.\n",
        "\n",
        "When you apply dropout to a layer, it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "Let's create a new neural network with `tf.keras.layers.Dropout` before training it using the augmented images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kyLe1Ms0nZ8u",
      "metadata": {
        "id": "kyLe1Ms0nZ8u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "def get_enhanced_model(input_shape):\n",
        "    x = Input(shape=input_shape)\n",
        "\n",
        "    augmented = (data_augmentation(input_shape))(x)\n",
        "\n",
        "    r = Rescaling(1./255)(augmented)\n",
        "\n",
        "    c1 = Conv2D(16, 3, padding='same', activation='relu')(r)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    c2 = Conv2D(32, 3, padding='same', activation='relu')(p1)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    c3 = Conv2D(64, 3, padding='same', activation='relu')(p2)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    d = Dropout(.2)(p3)\n",
        "    f = Flatten()(d)\n",
        "    d1 = Dense(128, activation='relu')(f)\n",
        "    d2 = Dense(num_classes)(d1)\n",
        "\n",
        "    model = Model(x, d2)\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = get_enhanced_model((d1, d2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jdDSUJhQoVWQ",
      "metadata": {
        "id": "jdDSUJhQoVWQ"
      },
      "outputs": [],
      "source": [
        "callback = EarlyStopping(monitor=\"val_accuracy\",\n",
        "    mode = \"max\",\n",
        "    min_delta=0.001,\n",
        "    patience=3,\n",
        "    restore_best_weights=True)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "history = model.fit(train_ds, epochs=15, validation_data = validation_ds, callbacks = [callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kD5YVjCSo_F3",
      "metadata": {
        "id": "kD5YVjCSo_F3"
      },
      "outputs": [],
      "source": [
        "display_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C_xKI1qSph5G",
      "metadata": {
        "id": "C_xKI1qSph5G"
      },
      "source": [
        "Let's try our model on images from a different set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GQr7a_nlpoQj",
      "metadata": {
        "id": "GQr7a_nlpoQj"
      },
      "outputs": [],
      "source": [
        "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
        "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sunflower_path, target_size=(d1, d2)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_ed-2b2Yqnhr",
      "metadata": {
        "id": "_ed-2b2Yqnhr"
      },
      "source": [
        "## Transfer learning and fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FrfxY9u7q_yy",
      "metadata": {
        "id": "FrfxY9u7q_yy"
      },
      "source": [
        "In this example, we will see how to apply transfer learning and fine-tuning exploiting a pre-trained network.\n",
        "\n",
        "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale classification task. You either use the pretrained model as it is or use transfer learning to customize this model to a given task.\n",
        "\n",
        "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n",
        "\n",
        "There are mainly two ways to use a pretrained model:\n",
        "\n",
        "1. Feature Extraction: Use the representations learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pretrained model so that you can repurpose the feature maps learned previously for the dataset.\n",
        "You do not need to (re)train the entire model. The base network already contains features that are generically useful for the task. However, the final classification part of the pretrained model is specific to the original classification task and subsequently specific to the set of classes on which the model was trained.\n",
        "\n",
        "1. Fine-Tuning: Unfreeze a few of the top layers of a frozen model base and jointly train both the newly-added classifier layers and the last layers of the base model. This allows us to \"fine-tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VQ_NusyRuTxG",
      "metadata": {
        "id": "VQ_NusyRuTxG"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "We will create the base model from the **MobileNet V2**, developed at Google. This is a pre-trained model on the ImageNet dataset, a large dataset consisting of 14M images and 1000 classes. ImageNet is a research training dataset with a wide variety of categories like `jackfruit` and `syringe`. This base of knowledge will help us classify images from our specific dataset.\n",
        "\n",
        "First, you need to pick which layer of MobileNet V2 you will use for feature extraction. The very last classification layer (on \"top\", as most diagrams of machine learning models go from bottom to top) is not very useful. Instead, you will follow the common practice to depend on the very last layer before the flatten operation. This layer is called the \"bottleneck layer\". The bottleneck layer features retain more generality as compared to the final/top layer.\n",
        "\n",
        "First, instantiate a MobileNet V2 model pre-loaded with weights trained on ImageNet. By specifying the **include_top=False** argument, you load a network that doesn't include the classification layers at the top, which is ideal for feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eRXaoyyMurdR",
      "metadata": {
        "id": "eRXaoyyMurdR"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(d1, d2, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SWHCexzrveq5",
      "metadata": {
        "id": "SWHCexzrveq5"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zwH0F7WVvQil",
      "metadata": {
        "id": "zwH0F7WVvQil"
      },
      "source": [
        "## Feature extraction\n",
        "In this step, we will freeze the convolutional base created from the previous step and to use as a feature extractor. Additionally, you add a classifier on top of it and train the top-level classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zc83VTlMvXXl",
      "metadata": {
        "id": "Zc83VTlMvXXl"
      },
      "source": [
        "It is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. MobileNet V2 has many layers, so setting the entire model's `trainable` flag to False will freeze all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TabU-jRDvS5Q",
      "metadata": {
        "id": "TabU-jRDvS5Q"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uC1mns3avi8E",
      "metadata": {
        "id": "uC1mns3avi8E"
      },
      "source": [
        "### Important note about BatchNormalization layers\n",
        "\n",
        "Many models contain `tf.keras.layers.BatchNormalization` layers. This layer is a special case and precautions should be taken in the context of fine-tuning, as shown later in this tutorial. \n",
        "\n",
        "When we set `layer.trainable = False`, the `BatchNormalization` layer will run in inference mode, and will not update its mean and variance statistics. \n",
        "\n",
        "When we unfreeze a model that contains BatchNormalization layers in order to do fine-tuning, we should keep the BatchNormalization layers in inference mode by passing `training = False` when calling the base model. Otherwise, the updates applied to the non-trainable weights will destroy what the model has learned.\n",
        "\n",
        "For more details, see the [Transfer learning guide](https://www.tensorflow.org/guide/keras/transfer_learning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HwVQ2wRZvt2v",
      "metadata": {
        "id": "HwVQ2wRZvt2v"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i3ObG2pnwIc8",
      "metadata": {
        "id": "i3ObG2pnwIc8"
      },
      "source": [
        "Let's add now the classification head layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ED2YsHVNwLxx",
      "metadata": {
        "id": "ED2YsHVNwLxx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "def get_t_l_model(input_shape):\n",
        "  input = tf.keras.Input(shape=input_shape)\n",
        "  aug = (data_augmentation(input_shape))(input)\n",
        "  r = Rescaling(1./127.5, offset=-1)(aug)\n",
        "  m_n = base_model(r, training = False)\n",
        "  gap = GlobalAveragePooling2D()(m_n)\n",
        "  d = Dropout(0.2)(gap)\n",
        "  out = Dense(num_classes)(d)\n",
        "  model = tf.keras.Model(input, out)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "model = get_t_l_model((d1, d2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zXk6w0UByKcN",
      "metadata": {
        "id": "zXk6w0UByKcN"
      },
      "outputs": [],
      "source": [
        "starting_lr = 1e-4\n",
        "initial_epochs = 10\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=starting_lr),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_history(history)"
      ],
      "metadata": {
        "id": "pN_A5Qq3SfZT"
      },
      "id": "pN_A5Qq3SfZT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tuning\n",
        "\n",
        "In the feature extraction experiment, you were only training a few layers on top of an MobileNetV2 base model. The weights of the pre-trained network were not updated during training.\n",
        "\n",
        "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n",
        "\n",
        "Also, you should try to fine-tune a small number of top layers rather than the whole MobileNet model. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning."
      ],
      "metadata": {
        "id": "yPR7aVqaSpXq"
      },
      "id": "yPR7aVqaSpXq"
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "Z1Ngb7-xS0ev"
      },
      "id": "Z1Ngb7-xS0ev",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the model \n",
        "\n",
        "As you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage. Otherwise, your model could overfit very quickly."
      ],
      "metadata": {
        "id": "jS5xFUd0TFKg"
      },
      "id": "jS5xFUd0TFKg"
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=starting_lr/10),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iQrZ6lbPTIrk"
      },
      "id": "iQrZ6lbPTIrk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = 10\n",
        "total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_ds)"
      ],
      "metadata": {
        "id": "QaZ3KVwDTT-9"
      },
      "id": "QaZ3KVwDTT-9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy'] += history_fine.history['accuracy']\n",
        "history.history['val_accuracy'] += history_fine.history['val_accuracy']\n",
        "\n",
        "history.history['loss'] += history_fine.history['loss']\n",
        "history.history['val_loss'] += history_fine.history['val_loss']\n",
        "\n",
        "display_history(history)"
      ],
      "metadata": {
        "id": "8-1xERuHUS22"
      },
      "id": "8-1xERuHUS22",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lecture_2_CNN_and_transfer_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
