{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnistDense.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8wSwJnsjx5P"
      },
      "source": [
        "# Mnist classification with NNs\n",
        "A first example of a simple Neural Network, applied to a well known dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wMZ2Ge6jw1E"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDiNppLVkvqd"
      },
      "source": [
        "Let us load the mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL8GyC0Nk14o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb5509c-8d5f-4a87-e9b8-3cf691280518"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijhDuLwwlQrI",
        "outputId": "02bca448-0ef7-4c42-cb00-20a6874082d0"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(\"pixel range is [{},{}]\".format(np.min(x_train),np.max(x_train)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "pixel range is [0,255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D01L64YcnWO5"
      },
      "source": [
        "We normalize the input in the range [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8uA2Kp7mG9s"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = np.reshape(x_train,(60000,28*28))\n",
        "x_test = np.reshape(x_test,(10000,28*28))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the network will be a proability distribution over the different categories. Similarly, we generate a ground truth distribution, and the training objective will consist in minimizing their distance (categorical crossentropy). The ground truth distribution is the so called \"categorical\" distribution: if x has label l, the corresponding categorical distribution has probaility 1 for the category l, and 0 for all the others."
      ],
      "metadata": {
        "id": "Yjrzmhgh3TZv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzWUm0UnODb",
        "outputId": "e0cf94cf-aabf-4d35-f84e-b481d72c10ec"
      },
      "source": [
        "print(y_train[0])\n",
        "y_train_cat = utils.to_categorical(y_train)\n",
        "print(y_train_cat[0])\n",
        "y_test_cat = utils.to_categorical(y_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfeZF3bUrFZf"
      },
      "source": [
        "Our first Netwok just implements logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBJtMj2pqJiR"
      },
      "source": [
        "xin = Input(shape=(784))\n",
        "res = Dense(10,activation='softmax')(xin)\n",
        "\n",
        "mynet = Model(inputs=xin,outputs=res)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXD5JT2ZrTJc",
        "outputId": "36886e01-b9bb-4729-a1ad-257e43f09726"
      },
      "source": [
        "mynet.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcjcOz8yrk5X"
      },
      "source": [
        "Now we need to compile the network.\n",
        "In order to do it, we need to pass two mandatory arguments:\n",
        "\n",
        "\n",
        "*   the **optimizer**, in charge of governing the details of the backpropagation algorithm\n",
        "*   the **loss function**\n",
        "\n",
        "Several predefined optimizers exist, and you should just choose your favourite one. A common choice is Adam, implementing an adaptive lerning rate, with momentum\n",
        "\n",
        "Optionally, we can specify additional metrics, mostly meant for monitoring the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XK20mAFrrkQ"
      },
      "source": [
        "mynet.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E58bT-Imvsw2"
      },
      "source": [
        "Finally, we fit the model over the trianing set. \n",
        "\n",
        "Fitting, just requires two arguments: training data e ground truth, that is x and y. Additionally we can specify epochs, batch_size, and many additional arguments.\n",
        "\n",
        "In particular, passing validation data allow the training procedure to measure loss and metrics on the validation set at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2woDXbbr6ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493cdebc-26fc-454f-d664-f1f1a60c1043"
      },
      "source": [
        "mynet.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 3ms/step - loss: 0.4714 - accuracy: 0.8756 - val_loss: 0.3093 - val_accuracy: 0.9148\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3039 - accuracy: 0.9152 - val_loss: 0.2808 - val_accuracy: 0.9213\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2837 - accuracy: 0.9205 - val_loss: 0.2730 - val_accuracy: 0.9227\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2729 - accuracy: 0.9237 - val_loss: 0.2699 - val_accuracy: 0.9254\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2669 - accuracy: 0.9257 - val_loss: 0.2681 - val_accuracy: 0.9254\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2619 - accuracy: 0.9278 - val_loss: 0.2662 - val_accuracy: 0.9281\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2579 - accuracy: 0.9285 - val_loss: 0.2648 - val_accuracy: 0.9284\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2555 - accuracy: 0.9297 - val_loss: 0.2631 - val_accuracy: 0.9275\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2529 - accuracy: 0.9303 - val_loss: 0.2666 - val_accuracy: 0.9256\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2509 - accuracy: 0.9308 - val_loss: 0.2619 - val_accuracy: 0.9279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1ff0656e50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0mBuorMulG5"
      },
      "source": [
        "xin = Input(shape=(784))\n",
        "x = Dense(128,activation='relu')(xin)\n",
        "res = Dense(10,activation='softmax')(x)\n",
        "\n",
        "mynet2 = Model(inputs=xin,outputs=res)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpMyvw7buzhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb66d7c4-39fa-4a9b-891d-ea7f1662bd41"
      },
      "source": [
        "mynet2.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYg0odW2u6cn"
      },
      "source": [
        "mynet2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDnzgIZVvGOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb25ba03-19bb-4197-de31-790e50c39cb5"
      },
      "source": [
        "mynet2.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2603 - accuracy: 0.9267 - val_loss: 0.1453 - val_accuracy: 0.9579\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1112 - accuracy: 0.9676 - val_loss: 0.1035 - val_accuracy: 0.9678\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0769 - accuracy: 0.9765 - val_loss: 0.0861 - val_accuracy: 0.9733\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0577 - accuracy: 0.9823 - val_loss: 0.0830 - val_accuracy: 0.9741\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.0860 - val_accuracy: 0.9745\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0358 - accuracy: 0.9885 - val_loss: 0.0789 - val_accuracy: 0.9759\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0777 - val_accuracy: 0.9784\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.0711 - val_accuracy: 0.9796\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0751 - val_accuracy: 0.9783\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0781 - val_accuracy: 0.9795\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1ff0540d90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcUKxCzKwzG9"
      },
      "source": [
        "An amazing improvement. WOW!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJr0EnAkw6nf"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1.   Add additional Dense layers and check the performance of the network\n",
        "2.   Replace 'relu' with different activation functions\n",
        "3. Adapt the network to work with the so called sparse_categorical_crossentropy\n",
        "4. the fit function return a history of training, with temporal sequences for all different metrics. Make a plot.\n",
        "\n"
      ]
    }
  ]
}
